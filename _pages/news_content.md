2024.06: Our paper: <a href='https://arxiv.org/abs/2211.13398'>CPPF++: Uncertainty-Aware Sim2Real Object Pose Estimation by Vote Aggregation</a> is accepted to <i>TPAMI 2024</i>! This is perhaps the most generalizable category-level pose estimation method you can find, and it only requires cheap synthetic data for training! <a href='https://arxiv.org/abs/2211.13398'>[Paper]</a> <a href='https://github.com/qq456cvb/CPPF2'>[Code]</a> <a href='/projects/cppf++'>[Project Page]</a>

2024.01: Our paper: <a href='https://arxiv.org/abs/2310.16838'>SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous Manipulation</a> is accepted to <i>ICLR 2024</i>! <a href='https://arxiv.org/abs/2310.16838'>[Paper]</a> <a href='https://halowangqx.github.io/SparseDFF'>[Code]</a>

2023.12: Our paper: <a href='https://arxiv.org/abs/2312.10714'>Primitive-based 3D Human-Object Interaction Modelling and Programming</a> is accepted to <i>AAAI 2024</i>! <a href='https://arxiv.org/abs/2312.10714'>[Paper]</a> <a href='https://mvig-rhos.com/p3haoi'>[Code]</a>

2023.03: Our paper: <a href='https://arxiv.org/abs/2303.03101'>CRIN: Rotation-Invariant Point Cloud Analysis and Rotation Estimation via Centrifugal Reference Frame</a> is accepted to <i>AAAI 2023</i> <b>Oral</b>! <a href='hhttps://arxiv.org/abs/2303.03101'>[Paper]</a> <a href='https://github.com/yokinglou/CRIN'>[Code]</a>

2022.03: Our paper: <a href='https://arxiv.org/abs/2011.11974'>UKPGAN: A General Self-Supervised Keypoint Detector</a> is accepted to <i>CVPR 2022</i>! <a href='https://arxiv.org/abs/2011.11974'>[Paper]</a> <a href='https://github.com/qq456cvb/UKPGAN'>[Code]</a> <a href='/projects/ukpgan'>[Project Page]</a>

2022.03: Our paper: <a href='https://arxiv.org/abs/2011.12001'>Canonical Voting: Towards Robust Oriented Bounding Box Detection in 3D Scenes</a> is accepted to <i>CVPR 2022</i>! <a href='https://arxiv.org/abs/2011.12001'>[Paper]</a> <a href='https://github.com/qq456cvb/CanonicalVoting'>[Code]</a> <a href='/projects/canonical-voting'>[Project Page]</a>

2022.03: Our paper: <a href='https://arxiv.org/abs/2203.03089'>CPPF: Towards Robust Category-Level 9D Pose Estimation in the Wild</a> is accepted to <i>CVPR 2022</i>! <a href='https://arxiv.org/abs/2203.03089'>[Paper]</a> <a href='https://github.com/qq456cvb/CPPF'>[Code]</a> <a href='/projects/cppf'>[Project Page]</a>

2021.11: Our paper: <a href='https://arxiv.org/abs/2102.12093'>PRIN/SPRIN: On Extracting Point-wise Rotation Invariant Features</a> is accepted to <i>TPAMI</i>, and to appear in the upcoming issues! <a href='https://arxiv.org/abs/2102.12093'>[Paper]</a> <a href='https://github.com/qq456cvb/SPRIN'>[Code]</a> <a href='/sprin'>[Project Page]</a>

2021.04: Our paper: <a href='https://arxiv.org/abs/2111.10817'>Understanding Pixel-level 2D Image Semantics with 3D Keypoint Knowledge Engine</a> is accepted to <i>TPAMI</i>, and to appear in the upcoming issues! <a href='https://arxiv.org/abs/2111.10817'>[Paper]</a> <a href='/pixel-understanding'>[Project Page]</a>

2021.02: Our paper <a href='https://arxiv.org/abs/2103.10814.pdf'>Skeleton Merger: an Unsupervised Aligned Keypoint Detector</a> is accepted as <i>CVPR</i> 2021 <b>Oral</b>! <a href='https://arxiv.org/abs/2103.10814'>[Paper]</a> <a href='https://github.com/eliphatfs/SkeletonMerger'>[Code]</a>

<!-- 2020.06: Our code and full dataset for <a href='/keypointnet'>KeypointNet</a> are released on <a href='https://github.com/qq456cvb/KeypointNet'>Github</a>! -->

2020.02: Our paper <a href='https://arxiv.org/abs/2002.12687'>KeypointNet: A Large-scale 3D Keypoint Dataset Aggregated from Numerous Human Annotations</a> is accepted to <i>CVPR</i> 2020! <a href='https://arxiv.org/abs/2002.12687'>[Paper]</a> <a href='https://github.com/qq456cvb/KeypointNet'>[Code]</a> <a href='/keypointnet'>[Project Page]</a>