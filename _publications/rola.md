---
title: "Robot Learning from Any Images"
collection: publications
permalink: /publications/rola
excerpt: 'RoLA is a framework that transforms any in-the-wild image into an interactive, physics-enabled robotic environment. It operates directly on a single image without requiring additional hardware or digital assets. RoLA democratizes robotic data generation by producing massive visuomotor robotic demonstrations within minutes from a wide range of image sources.'
date: '2025-09-26'
venue: 'CoRL 2025'
weight: 1000
code: 'https://github.com/PointsCoder/OpenReal2Sim'
arxiv: 'https://arxiv.org/abs/2509.22970'
site: 'https://sihengz02.github.io/RoLA/'
citation: 'Zhao, S., Mao, J., Chow, W., Shangguan, Z., Shi, T., Xue, R., Zheng, Y., Weng, Y., You, Y., Seita, D., Guibas, L., Zakharov, S., Guizilini, V., & Wang, Y. (2025). Robot Learning from Any Images. CoRL 2025.'
authors: 'Siheng Zhao, Jiageng Mao, Wei Chow, Zeyu Shangguan, Tianheng Shi, Rong Xue, Yuxi Zheng, Yijia Weng, <b>Yang You</b>, Daniel Seita, Leonidas Guibas, Sergey Zakharov, Vitor Guizilini, Yue Wang'
---

